{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "import numpy as np\n",
    "import time\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from keras_regressor import compileModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>requests</th>\n",
       "      <th>tempC</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>WindGustKmph</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-09-01 00:00:00</th>\n",
       "      <td>708</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-01 01:00:00</th>\n",
       "      <td>479</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-01 02:00:00</th>\n",
       "      <td>492</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-01 03:00:00</th>\n",
       "      <td>563</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-01 04:00:00</th>\n",
       "      <td>355</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     requests  tempC  precipMM  WindGustKmph\n",
       "request_date                                                \n",
       "2015-09-01 00:00:00       708   16.0       0.0          17.0\n",
       "2015-09-01 01:00:00       479   16.0       0.0          17.0\n",
       "2015-09-01 02:00:00       492   15.0       0.0          18.0\n",
       "2015-09-01 03:00:00       563   15.0       0.0          18.0\n",
       "2015-09-01 04:00:00       355   16.0       0.0          15.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/totaldf.csv\", index_col='request_date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexCol = 'request_date'\n",
    "stepsIn = 504\n",
    "stepsOut = 168\n",
    "testsize =stepsIn+stepsOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, 0]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "computeCols = [col for col in df.columns if col!=indexCol]\n",
    "df[computeCols] = df[computeCols].astype('float32')\n",
    "\n",
    "# Scale & Formulate as a Supervised  Learning method\n",
    "scalers = []\n",
    "df2 = pd.DataFrame(columns = df.columns, index=df.index)\n",
    "for col in df.columns:\n",
    "    scaler = StandardScaler()\n",
    "    df2[col] = scaler.fit_transform(np.array(df[col]).reshape(-1, 1))\n",
    "    scalers.append(scaler)\n",
    "\n",
    "scaler = scalers[0]\n",
    "data = np.array(df2)\n",
    "X, Y = split_sequences(data, stepsIn, stepsOut)\n",
    "\n",
    "# Train/set split\n",
    "trainsize = len(df2)-testsize\n",
    "train_X = X[:trainsize, :]\n",
    "train_Y = Y[:trainsize]\n",
    "test_X = X[trainsize:, :]\n",
    "test_Y = Y[trainsize:]\n",
    "train_X = train_X.reshape((train_X.shape[0], train_X.shape[1], df2.shape[1]))   # reshape for LSTM input\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], df2.shape[1]))\n",
    "inputshape = train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Best model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_cv = {'L2': 0, 'alpha': 0.1, 'batch_size': 128, 'dropout': 0.3, \n",
    "                  'epochs': 10, 'learning_rate': 0.01, 'optimizer': 'adam'}   # discovered through GridSearchCV\n",
    "\n",
    "l2_reg = 0\n",
    "alpha = 0.1\n",
    "batch_size = 128\n",
    "dropout = 0.3\n",
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2233 samples\n",
      "Epoch 1/10\n",
      "2233/2233 [==============================] - 866s 388ms/sample - loss: 0.5116 - mean_absolute_error: 0.5116\n",
      "Epoch 2/10\n",
      "2233/2233 [==============================] - 884s 396ms/sample - loss: 0.4633 - mean_absolute_error: 0.4633\n",
      "Epoch 3/10\n",
      "2233/2233 [==============================] - 1025s 459ms/sample - loss: 0.4492 - mean_absolute_error: 0.4492\n",
      "Epoch 4/10\n",
      "2233/2233 [==============================] - 1017s 455ms/sample - loss: 0.4385 - mean_absolute_error: 0.4385\n",
      "Epoch 5/10\n",
      "2233/2233 [==============================] - 992s 444ms/sample - loss: 0.4278 - mean_absolute_error: 0.4278\n",
      "Epoch 6/10\n",
      "2233/2233 [==============================] - 1008s 451ms/sample - loss: 0.4242 - mean_absolute_error: 0.4242\n",
      "Epoch 7/10\n",
      "2233/2233 [==============================] - 994s 445ms/sample - loss: 0.4170 - mean_absolute_error: 0.4170\n",
      "Epoch 8/10\n",
      "2233/2233 [==============================] - 998s 447ms/sample - loss: 0.4109 - mean_absolute_error: 0.4109\n",
      "Epoch 9/10\n",
      "2233/2233 [==============================] - 953s 427ms/sample - loss: 0.4075 - mean_absolute_error: 0.4075\n",
      "Epoch 10/10\n",
      "2233/2233 [==============================] - 895s 401ms/sample - loss: 0.4055 - mean_absolute_error: 0.4055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x251c09e8348>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compileModel(epochs, l2_reg, alpha, batch_size, dropout, \n",
    "    learning_rate, optimizer, init='glorot_uniform'):\n",
    "    input_shape = (2233, 504, 4) \n",
    "    model = Sequential()                           # LSTM input layer MUST be 3D - (samples, timesteps, features)\n",
    "    model.add(LSTM(504,\n",
    "                #return_sequences=True,          # necessary for stacked LSTM layers\n",
    "            input_shape=(input_shape[1], input_shape[2])))\n",
    "    #model.add(LSTM(10))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256, \n",
    "            kernel_initializer = init,\n",
    "            kernel_regularizer=l2(l2_reg), \n",
    "            activation=LeakyReLU(alpha=alpha)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(168))\n",
    "\n",
    "    model.compile(loss='mean_absolute_error', optimizer=optimizer, metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "model = compileModel(epochs, l2_reg, alpha, batch_size, dropout, learning_rate, optimizer)\n",
    "\n",
    "model.fit(train_X, train_Y, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 0.6790000200271606\n"
     ]
    }
   ],
   "source": [
    "pred_Y = model.predict(test_X)\n",
    "test_score = round(mean_absolute_error(test_Y, pred_Y),3)\n",
    "print(\"Test MAE: {s}\".format(s=test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./final_keras.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "parallel = 2\n",
    "paramGrid = {\n",
    "        'epochs': [5, 10],\n",
    "        'L2': [0, 0.1, 0.3],\n",
    "        'alpha': [0.01, 0.1, 0.3],\n",
    "        'batch_size': [64, 128],\n",
    "        'dropout': [0.3, 0.5, 0.1],\n",
    "        'learning_rate': [0.01, 0.001],\n",
    "        'optimizer': ['adam']\n",
    "      }\n",
    "\n",
    "combinations = list(itertools.product(*list(paramGrid.values())))\n",
    "print(len(combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 2233 samples\n",
      "Epoch 1/10\n",
      "2233/2233 [==============================] - 248s 111ms/sample - loss: 0.5106 - mean_absolute_error: 0.5106\n",
      "Epoch 2/10\n",
      "2233/2233 [==============================] - 360s 161ms/sample - loss: 0.4631 - mean_absolute_error: 0.4631\n",
      "Epoch 3/10\n",
      "2233/2233 [==============================] - 404s 181ms/sample - loss: 0.4452 - mean_absolute_error: 0.4452\n",
      "Epoch 4/10\n",
      "2233/2233 [==============================] - 456s 204ms/sample - loss: 0.4326 - mean_absolute_error: 0.4326\n",
      "Epoch 5/10\n",
      "2233/2233 [==============================] - 585s 262ms/sample - loss: 0.4299 - mean_absolute_error: 0.4299\n",
      "Epoch 6/10\n",
      "2233/2233 [==============================] - 712s 319ms/sample - loss: 0.4195 - mean_absolute_error: 0.4195\n",
      "Epoch 7/10\n",
      "2233/2233 [==============================] - 709s 317ms/sample - loss: 0.4136 - mean_absolute_error: 0.4136\n",
      "Epoch 8/10\n",
      "2233/2233 [==============================] - 754s 338ms/sample - loss: 0.4103 - mean_absolute_error: 0.4103\n",
      "Epoch 9/10\n",
      "2233/2233 [==============================] - 803s 360ms/sample - loss: 0.4052 - mean_absolute_error: 0.4052\n",
      "Epoch 10/10\n",
      "2233/2233 [==============================] - 898s 402ms/sample - loss: 0.4011 - mean_absolute_error: 0.4011\n",
      "Best parameter set found: {'L2': 0, 'alpha': 0.1, 'batch_size': 128, 'dropout': 0.3, 'epochs': 10, 'learning_rate': 0.01, 'optimizer': 'adam'}\n",
      "Best KerasRegressor MAE score 0.6200819611549377\n",
      "Elapsed time: 11500.71 seconds for [(10, 0, 0.1, 128, 0.3, 0.01, 'adam'), (10, 0, 0.3, 128, 0.3, 0.01, 'adam')] models\n"
     ]
    }
   ],
   "source": [
    "modelname = 'keras_regressor.h5'\n",
    "paramname = 'keras_regressor_best_params.json'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "paramGrid = {\n",
    "        'epochs': [10],\n",
    "        'L2': [0],#, 0.1, 0.3],\n",
    "        'alpha': [0.1, 0.3],\n",
    "        'batch_size': [128],\n",
    "        'dropout': [0.3],\n",
    "        'learning_rate': [0.01],\n",
    "        'optimizer': ['adam']\n",
    "      }\n",
    "\n",
    "k_fold = KFold(n_splits=2)   \n",
    "combinations = list(itertools.product(*list(paramGrid.values())))\n",
    "\n",
    "\n",
    "grid = GridSearchCV(KerasRegressor(build_fn=compileModel, \n",
    "                                    verbose=1), \n",
    "                    param_grid=paramGrid, \n",
    "                    scoring='neg_mean_absolute_error',            # ignore minority class size, treat as equal\n",
    "                    n_jobs=parallel, \n",
    "                    return_train_score=True, \n",
    "                    refit='neg_mean_absolute_error',              # refit based on score of f1_scorer\n",
    "                    cv=k_fold) \n",
    "\n",
    "grid_result = grid.fit(train_X, train_Y)\n",
    "    \n",
    "bestParameters = grid_result.best_params_\n",
    "print(\"Best parameter set found:\", bestParameters)\n",
    "\n",
    "best_model = grid_result.best_estimator_.model\n",
    "best_model_history = grid_result.best_estimator_.model.history.history\n",
    "\n",
    "pred_Y = best_model.predict(test_X)\n",
    "\n",
    "print(\"Best KerasRegressor MAE score {s}\".format(s=mean_absolute_error(test_Y, pred_Y)))\n",
    "\n",
    "end = time.time()\n",
    "elapsed = round(end-start,3)\n",
    "print(\"Elapsed time: {s} seconds for {c} models\".format(s=elapsed, c=len(combinations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save('./gscv_best_lstm.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
