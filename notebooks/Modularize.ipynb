{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 finalize plots in TS analysis and save them to default shit\n",
    "# 3 fix model stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import warnings\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, datapath='./routes.csv', weatherdata='./enrichment/lima_2015_weatherdata.csv'):\n",
    "        self.datapath = datapath\n",
    "        assert os.path.exists(self.datapath)\n",
    "        self.__setmissingpath(\"./cleaning\")\n",
    "        self.__setweatherpath(weatherdata)                     # additional data to enrich the dataset\n",
    "        df = pd.read_csv(\"./routes.csv\", sep='\\t')\n",
    "                              \n",
    "        df = self.cleanData(df)\n",
    "        self.__setData(df)\n",
    "        self.__setResampledData__(self.mergeWeatherData(df))           # after cleaning & merging\n",
    "    \n",
    "    def getData(self):\n",
    "        return self.__data\n",
    "    \n",
    "    def getResampledData(self):\n",
    "        return self.__resampledData\n",
    "                              \n",
    "    def getmissingpath(self):\n",
    "        return self.__missingpath\n",
    "    \n",
    "    def getweatherpath(self):\n",
    "        return self.__weatherdata\n",
    "   \n",
    "    def __setData(self, df):\n",
    "        self.__data = df\n",
    "\n",
    "    def __setResampledData__(self, df):\n",
    "        self.__resampledData = df\n",
    "        \n",
    "    def __setmissingpath(self, path):\n",
    "        self.__missingpath = path\n",
    "        \n",
    "    def __setweatherpath(self, path):\n",
    "        self.__weatherdata = path\n",
    "        \n",
    "    def cleanData(self, df):\n",
    "        print(\"Cleaning the Data...\")\n",
    "        sns_plot = sns.heatmap(df.isnull(), yticklabels=False, cbar=True, cmap='viridis'\n",
    "           #,vmax=1.0, vmin=-1.0   # these solve the boolean - problem\n",
    "           )\n",
    "        if not os.path.exists(self.getmissingpath()):\n",
    "            os.mkdir(self.getmissingpath())\n",
    "        fig = sns_plot.figure.savefig(self.getmissingpath()+\"/missingdata.png\")\n",
    "        plt.close(fig)\n",
    "        print(\"We have \"+str(np.around(len(df[df.isnull().any(axis=1)])/len(df)*100, decimals=3))+\"% missing values so we drop them\")    #def loadWeatherData(self):\n",
    "        df = df.dropna()\n",
    "        return df\n",
    "      \n",
    "    def loadWeatherData(self):\n",
    "        \"\"\"\n",
    "        Hourly sampled dataset with temperature, wind and rain information\n",
    "        \"\"\"\n",
    "        print(\"Loading additional weather data...\")\n",
    "        assert os.path.exists(self.getweatherpath())\n",
    "        weatherdf = pd.read_csv(self.getweatherpath())\n",
    "        return weatherdf\n",
    "        \n",
    "    def mergeWeatherData(self, df):\n",
    "        print(\"Enriching...\")\n",
    "        dfw = self.loadWeatherData()\n",
    "        #Resample df to a frequency of an hour\n",
    "        df[\"request_date\"]= pd.to_datetime(df[\"request_date\"]) \n",
    "        df = df.resample('h', on = 'request_date').count()\n",
    "        df = df.rename(columns={'passenger_id': 'requests'})\n",
    "        df = df[['requests']]\n",
    "\n",
    "        # Reset Indexes to merge\n",
    "        df = df.reset_index()  \n",
    "        dfw = dfw.reset_index()\n",
    "        \n",
    "        dfw['datetime'] = pd.to_datetime(dfw['datetime'])\n",
    "        df = df.merge(dfw, left_on='request_date', right_on='datetime', how='left')\n",
    "        df = df.fillna(df.mean())                                        # impute 6 missing values with mean\n",
    "        df.drop(columns=['datetime', 'index'], inplace=True)                      # remove 2nd index\n",
    "        \n",
    "        # try to reindex\n",
    "        df = df.set_index('request_date')\n",
    "        df = df.asfreq(freq='h')    \n",
    "        \n",
    "        #print(\"new size is \"+str(len(df)))\n",
    "        return df\n",
    "        \n",
    "\n",
    "class Cluster_Analysis():\n",
    "    def __init__(self, df, clusterpath='./clustering', explore=False):\n",
    "        self.__setClusterpath__(clusterpath) \n",
    "        self.__setData__(df)\n",
    "        if explore!=False:\n",
    "            self.clusterExploration(df, 'source')\n",
    "            self.clusterExploration(df, 'destination')\n",
    "        df = self.clusterData(df)\n",
    "        self.drawClustersOnMap(df, 'source')\n",
    "        self.drawClustersOnMap(df, 'destination')\n",
    "    \n",
    "    def getData(self):\n",
    "        return self.__data\n",
    "    \n",
    "    def __setData__(self, df):\n",
    "        self.__data = df\n",
    "    \n",
    "    def getClusterpath(self):\n",
    "        return self.__clusterpath\n",
    "                              \n",
    "    def __setClusterpath__(self, path):\n",
    "        self.__clusterpath = path \n",
    "                              \n",
    "    def clusterExploration(self, df_geo, kind):\n",
    "        performanceList = []\n",
    "        K = range(5,30)\n",
    "        \"\"\"\n",
    "        Trains K-means to the coordinates and exports elbow diagram to outputfolder\n",
    "        Arguments:\n",
    "            df: Input dataframe\n",
    "            kind (string): 'source' or 'destination'\n",
    "            outputfolder (string): folder to export elbow diagram\n",
    "        Returns:\n",
    "            data (pd.DataFrame): new dataframe with two new columns\n",
    "            with the predicted source and destination based on the clustering\n",
    "            algorithm\n",
    "        \"\"\"\n",
    "        assert kind=='source' or kind=='destination'\n",
    "        print(\"Exploring K for KMeans for \"+str(kind)+\" coordinates...\")\n",
    "        df_geo = df_geo[[str(kind)+'_longitude', str(kind)+'_longitude']]\n",
    "        \n",
    "        # Explore K\n",
    "        for k in K:\n",
    "            kmeanModel = KMeans(n_clusters=k, n_jobs=-1).fit(df_geo)\n",
    "            #distortions.append(sum(np.min(cdist(df_geo, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / df_geo.shape[0])\n",
    "            performanceList.append(kmeanModel.inertia_)\n",
    "            \n",
    "        # Plot the elbow\n",
    "        plt.plot(K, performanceList, 'bx-')\n",
    "        plt.xlabel('k')\n",
    "        plt.ylabel('Sum of squared distances')\n",
    "        plt.title('Error vs K in '+str(kind)+' coordinates')\n",
    "        if not os.path.exists(self.clusterpath):\n",
    "            os.mkdir(outputfolder)\n",
    "        plt.savefig(self.clusterpath+'/elbow_rule_'+str(kind)+'.png')\n",
    "        #plt.show()\n",
    "        \n",
    "    def clusterData(self, df, k=15):                                    # default after elbow rule\n",
    "        print(\"Performing K-means for both source and destination coordinates with K=\"+str(k))\n",
    "        kmeans_model = KMeans(n_clusters=k, n_jobs=-1).fit(df[['source_latitude', 'source_longitude']])\n",
    "        df['sourceCluster'] = kmeans_model.predict(df[['source_latitude', 'source_longitude']])\n",
    "\n",
    "        kmeans_model = KMeans(n_clusters=k, n_jobs=-1).fit(df[['destination_latitude', 'destination_longitude']])\n",
    "        df['destinationCluster'] = kmeans_model.predict(df[['destination_latitude', 'destination_longitude']])\n",
    "        return df\n",
    "\n",
    "    def calculateBoarders(self, df, decimals=4):\n",
    "        # Needed to download Lima map from https://www.openstreetmap.org/export#map=5/51.500/-0.100\n",
    "\n",
    "        sourceDict = {'longitude_max': np.around(df['source_longitude'].max(), decimals=decimals), \n",
    "                      'longitude_min': np.around(df['source_longitude'].min(), decimals=decimals), \n",
    "                      'latitude_max': np.around(df['source_latitude'].max(), decimals=decimals), \n",
    "                      'latitude_min': np.around(df['source_latitude'].min(), decimals=decimals)}\n",
    "\n",
    "        destinationDict = {'longitude_max': np.around(df['destination_longitude'].max(), decimals=decimals), \n",
    "                      'longitude_min': np.around(df['destination_longitude'].min(), decimals=decimals), \n",
    "                      'latitude_max': np.around(df['destination_latitude'].max(), decimals=decimals), \n",
    "                      'latitude_min': np.around(df['destination_latitude'].min(), decimals=decimals)}\n",
    "        \n",
    "        \n",
    "    def drawClustersOnMap(self, df, kind, photopath='./limaMap.png'):\n",
    "        assert (kind=='source') or (kind=='destination')\n",
    "        assert os.path.exists(photopath)\n",
    "    \n",
    "        print(\"Generating Cluster Map for \"+str(kind)+\" coordinates...\")\n",
    "        clusters = len(df[str(kind)+'Cluster'].unique())\n",
    "        x = np.arange(clusters+1)                         # used for different colors of clusters\n",
    "        ys = [i+x+(i*x)**2 for i in range(clusters+1)]\n",
    "        colors = matplotlib.cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "\n",
    "\n",
    "        ruh_m = plt.imread(photopath)\n",
    "\n",
    "        BBox = ((df[str(kind)+'_longitude'].min(),   \n",
    "                 df[str(kind)+'_longitude'].max(),      \n",
    "                 df[str(kind)+'_latitude'].min(), \n",
    "                 df[str(kind)+'_latitude'].max()))\n",
    "\n",
    "        fig, ax = plt.subplots(figsize = (8,7))\n",
    "\n",
    "        # For all Clusters\n",
    "\n",
    "        num=0\n",
    "        #for k,c in zip(df['pred_'+str(sd)].unique(), colors):\n",
    "        for k in df[str(kind)+'Cluster'].unique():\n",
    "            #num+=1\n",
    "\n",
    "            ax.scatter(df[df[str(kind)+'Cluster']==k][str(kind)+'_longitude'], \n",
    "                       df[df[str(kind)+'Cluster']==k][str(kind)+'_latitude'], \n",
    "                       zorder=1, alpha= 0.2, c=[np.random.rand(3,)], s=10)                  # random color\n",
    "            #print(num)\n",
    "\n",
    "        ax.set_title('Plotting Spatial Data on Lima Map')\n",
    "        ax.set_xlim(BBox[0],BBox[1])\n",
    "        ax.set_ylim(BBox[2],BBox[3])\n",
    "        ax.imshow(ruh_m, zorder=0, extent = BBox, aspect= 'equal')\n",
    "        fig.savefig(str(self.getClusterpath())+'/Clustermap_'+str(kind)+'.png')\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "class TS_Analysis():    # add export of plots\n",
    "    def __init__(self, df, exportpath='./TS Decomposition/'):\n",
    "        self.__setData__(df)\n",
    "        self.__setExportPath__(exportpath)\n",
    "        #self.plotTS()\n",
    "        #self.TSDecomposition()  \n",
    "        self.__setTestResults__(self.stationarityTests())\n",
    "        \n",
    "    def getExportPath(self):\n",
    "        return self.__exportpath\n",
    "        \n",
    "    def __setData__(self, df):\n",
    "        self.__data = df\n",
    "        \n",
    "    def __setTestResults__(self, df):\n",
    "        self.__testResults = df\n",
    "        \n",
    "    def __setExportPath__(self, exportpath):\n",
    "        self.__exportpath = exportpath\n",
    "        \n",
    "    def getData(self):\n",
    "        return self.__data\n",
    "    \n",
    "    def getTestResults(self):\n",
    "        return self.__testResults\n",
    "                    \n",
    "    def plotTS(self):\n",
    "        df = self.getData()\n",
    "        #df.reset_index(inplace=True)\n",
    "        fig, axs = plt.subplots(nrows=4, ncols=1, figsize=(15,15))\n",
    "        figure = sns.lineplot(x='request_date', y='requests', color=\"indianred\", data=dfl, ax=axs[0])\n",
    "        for item in figure.get_xticklabels():\n",
    "            item.set_rotation(45)\n",
    "        figure = sns.lineplot(x='request_date', y='Temperature', color=\"blue\", data=dfl, ax=axs[1])\n",
    "        for item in figure.get_xticklabels():\n",
    "            item.set_rotation(45)\n",
    "        figure = sns.lineplot(x='request_date', y='Precipitation', color=\"green\", data=dfl, ax=axs[2])\n",
    "        for item in figure.get_xticklabels():\n",
    "            item.set_rotation(45)\n",
    "        figure = sns.lineplot(x='request_date', y='WindSpeed', color=\"black\", data=dfl, ax=axs[3])\n",
    "        for item in figure.get_xticklabels():\n",
    "            item.set_rotation(45)\n",
    "        plt.savefig(self.getExportPath()+\"./plots.png\")\n",
    "        plt.close(fig)\n",
    "                    \n",
    "    def TSDecomposition(self):                                   # examine trend, seasonality\n",
    "        rcParams['figure.figsize'] = 18, 8\n",
    "        print(\"Exporting Time Series Decomposition...\")\n",
    "        usefulcols = ['requests', 'Temperature', 'Precipitation', 'WindSpeed']  \n",
    "        # assess columns?\n",
    "        df = self.getData()\n",
    "        #df.reset_index(inplace=True)\n",
    "        for col in usefulcols:                           # do it for all relevant TS columns\n",
    "            temp = df[['request_date', col]]\n",
    "            temp = temp.set_index('request_date')\n",
    "            temp = temp.asfreq(freq='h')\n",
    "            \n",
    "            decomposition = sm.tsa.seasonal_decompose(temp, model='additive')\n",
    "            fig = decomposition.plot()\n",
    "            fig.savefig(self.getExportPath()+str(col)+'_decomposition.png')\n",
    "            plt.close(fig)\n",
    "            #plt.show()\n",
    "    \n",
    "    def kpss_test(self, timeseries):\n",
    "        #print ('Results of KPSS Test:')\n",
    "        kpsstest = kpss(timeseries, regression='c')\n",
    "        kpss_output = pd.Series(kpsstest[0:3], index=['Test Statistic','p-value','Lags Used'])\n",
    "        for key,value in kpsstest[3].items():\n",
    "            kpss_output['Critical Value (%s)'%key] = value\n",
    "        #print (kpss_output)\n",
    "        return kpss_output\n",
    "    \n",
    "    def adf_test(self, timeseries):    # The more negative the Test Statistic is, the harder we reject H0: unit root/stationary\n",
    "        #Perform Dickey-Fuller test:                 # equally: H0: TS is non-stationary\n",
    "        #print ('Results of Dickey-Fuller Test:')\n",
    "        dftest = adfuller(timeseries, autolag='AIC')\n",
    "        dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','Lags Used','Number of Observations Used'])\n",
    "        for key,value in dftest[4].items():\n",
    "            dfoutput['Critical Value (%s)'%key] = value\n",
    "        #print (dfoutput) \n",
    "        return dfoutput\n",
    "    \n",
    "    def stationarityTests(self):        # check for stationarity to determine whether its necessary to transform\n",
    "        df = self.getData()             # (log, boxcox) for forecasting\n",
    "        dftest = pd.DataFrame()\n",
    "        for col in df.columns:                # return all results for both tests and all TS in a dataframe\n",
    "            dfadf = self.adf_test(df[col]) \n",
    "            row = pd.Series({'H0 Rejected':True if dfadf.loc['p-value'] <= 0.05 else False})   # result of the test\n",
    "            dfadf = dfadf.append(row)\n",
    "            \n",
    "            dfkpss = self.kpss_test(df[col])\n",
    "            row = pd.Series({'H0 Rejected':True if dfkpss.loc['p-value'] <= 0.05 else False})  # result of the test\n",
    "            dfkpss = dfkpss.append(row)\n",
    "            \n",
    "            dftest[col,'ADF'] = dfadf\n",
    "            dftest[col,'KPSS'] = dfkpss\n",
    "        return dftest\n",
    "        \n",
    "              \n",
    "# if main ...        \n",
    "        \n",
    "cluster=False     \n",
    "#cluster=True\n",
    "        \n",
    "\n",
    "#loader = DataLoader()\n",
    "if cluster:\n",
    "    sample = loader.getData().sample(frac=0.01)\n",
    "    Cluster_Analysis(sample)\n",
    "tsa = TS_Analysis(loader.getResampledData())\n",
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(requests, ADF)</th>\n",
       "      <th>(requests, KPSS)</th>\n",
       "      <th>(Temperature, ADF)</th>\n",
       "      <th>(Temperature, KPSS)</th>\n",
       "      <th>(Precipitation, ADF)</th>\n",
       "      <th>(Precipitation, KPSS)</th>\n",
       "      <th>(WindSpeed, ADF)</th>\n",
       "      <th>(WindSpeed, KPSS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test Statistic</th>\n",
       "      <td>-4.821514</td>\n",
       "      <td>3.585869</td>\n",
       "      <td>-3.409897</td>\n",
       "      <td>5.917476</td>\n",
       "      <td>-9.338873e+00</td>\n",
       "      <td>0.238714</td>\n",
       "      <td>-7.526968e+00</td>\n",
       "      <td>0.707040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p-value</th>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010626</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>8.908239e-16</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.663009e-11</td>\n",
       "      <td>0.012905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lags Used</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>2.700000e+01</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Observations Used</th>\n",
       "      <td>2876.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2876.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.876000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.877000e+03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Critical Value (1%)</th>\n",
       "      <td>-3.432626</td>\n",
       "      <td>0.739000</td>\n",
       "      <td>-3.432626</td>\n",
       "      <td>0.739000</td>\n",
       "      <td>-3.432626e+00</td>\n",
       "      <td>0.739000</td>\n",
       "      <td>-3.432625e+00</td>\n",
       "      <td>0.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Critical Value (5%)</th>\n",
       "      <td>-2.862545</td>\n",
       "      <td>0.463000</td>\n",
       "      <td>-2.862545</td>\n",
       "      <td>0.463000</td>\n",
       "      <td>-2.862545e+00</td>\n",
       "      <td>0.463000</td>\n",
       "      <td>-2.862545e+00</td>\n",
       "      <td>0.463000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Critical Value (10%)</th>\n",
       "      <td>-2.567305</td>\n",
       "      <td>0.347000</td>\n",
       "      <td>-2.567305</td>\n",
       "      <td>0.347000</td>\n",
       "      <td>-2.567305e+00</td>\n",
       "      <td>0.347000</td>\n",
       "      <td>-2.567305e+00</td>\n",
       "      <td>0.347000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H0 Rejected</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             (requests, ADF)  (requests, KPSS)  \\\n",
       "Test Statistic                     -4.821514          3.585869   \n",
       "p-value                             0.000049          0.010000   \n",
       "Lags Used                          28.000000         28.000000   \n",
       "Number of Observations Used      2876.000000               NaN   \n",
       "Critical Value (1%)                -3.432626          0.739000   \n",
       "Critical Value (5%)                -2.862545          0.463000   \n",
       "Critical Value (10%)               -2.567305          0.347000   \n",
       "H0 Rejected                         1.000000          1.000000   \n",
       "\n",
       "                             (Temperature, ADF)  (Temperature, KPSS)  \\\n",
       "Test Statistic                        -3.409897             5.917476   \n",
       "p-value                                0.010626             0.010000   \n",
       "Lags Used                             28.000000            28.000000   \n",
       "Number of Observations Used         2876.000000                  NaN   \n",
       "Critical Value (1%)                   -3.432626             0.739000   \n",
       "Critical Value (5%)                   -2.862545             0.463000   \n",
       "Critical Value (10%)                  -2.567305             0.347000   \n",
       "H0 Rejected                            1.000000             1.000000   \n",
       "\n",
       "                             (Precipitation, ADF)  (Precipitation, KPSS)  \\\n",
       "Test Statistic                      -9.338873e+00               0.238714   \n",
       "p-value                              8.908239e-16               0.100000   \n",
       "Lags Used                            2.800000e+01              28.000000   \n",
       "Number of Observations Used          2.876000e+03                    NaN   \n",
       "Critical Value (1%)                 -3.432626e+00               0.739000   \n",
       "Critical Value (5%)                 -2.862545e+00               0.463000   \n",
       "Critical Value (10%)                -2.567305e+00               0.347000   \n",
       "H0 Rejected                          1.000000e+00               0.000000   \n",
       "\n",
       "                             (WindSpeed, ADF)  (WindSpeed, KPSS)  \n",
       "Test Statistic                  -7.526968e+00           0.707040  \n",
       "p-value                          3.663009e-11           0.012905  \n",
       "Lags Used                        2.700000e+01          28.000000  \n",
       "Number of Observations Used      2.877000e+03                NaN  \n",
       "Critical Value (1%)             -3.432625e+00           0.739000  \n",
       "Critical Value (5%)             -2.862545e+00           0.463000  \n",
       "Critical Value (10%)            -2.567305e+00           0.347000  \n",
       "H0 Rejected                      1.000000e+00           1.000000  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest = tsa.getTestResults()\n",
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(requests, ADF)           True\n",
       "(requests, KPSS)          True\n",
       "(Temperature, ADF)        True\n",
       "(Temperature, KPSS)       True\n",
       "(Precipitation, ADF)      True\n",
       "(Precipitation, KPSS)    False\n",
       "(WindSpeed, ADF)          True\n",
       "(WindSpeed, KPSS)         True\n",
       "Name: p-value, dtype: bool"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.loc['p-value'] <= 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>source_latitude</th>\n",
       "      <th>source_longitude</th>\n",
       "      <th>source_address</th>\n",
       "      <th>destination_latitude</th>\n",
       "      <th>destination_longitude</th>\n",
       "      <th>destination_address</th>\n",
       "      <th>request_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41037</td>\n",
       "      <td>-12.088156</td>\n",
       "      <td>-77.016065</td>\n",
       "      <td>Avenida Nicolás de Arriola 314, La Victoria 13</td>\n",
       "      <td>-12.108531</td>\n",
       "      <td>-77.044891</td>\n",
       "      <td>Calle Carlos Graña Elisande 340, San Isidro 27</td>\n",
       "      <td>2015-09-01 00:00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116591</td>\n",
       "      <td>-12.099957</td>\n",
       "      <td>-77.036497</td>\n",
       "      <td>Av Los Conquistadores 392, San Isidro 15073</td>\n",
       "      <td>-12.119686</td>\n",
       "      <td>-76.999969</td>\n",
       "      <td>Bruselas 228, La Calera De La Merced</td>\n",
       "      <td>2015-09-01 00:00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86426</td>\n",
       "      <td>-12.099153</td>\n",
       "      <td>-77.019425</td>\n",
       "      <td>Av. República de Panamá 3537, San Isidro 27</td>\n",
       "      <td>-12.076505</td>\n",
       "      <td>-77.089305</td>\n",
       "      <td>Av. La Marina cdra. 25, San Miguel 32</td>\n",
       "      <td>2015-09-01 00:00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53610</td>\n",
       "      <td>-12.110271</td>\n",
       "      <td>-77.028945</td>\n",
       "      <td>Junín 225, Miraflores</td>\n",
       "      <td>-12.132221</td>\n",
       "      <td>-77.027021</td>\n",
       "      <td>Calle San Fernando 380, Miraflores 18</td>\n",
       "      <td>2015-09-01 00:00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102927</td>\n",
       "      <td>-12.098430</td>\n",
       "      <td>-77.026246</td>\n",
       "      <td>Av. República De Colombia 791, San Isidro</td>\n",
       "      <td>-12.099529</td>\n",
       "      <td>-76.990486</td>\n",
       "      <td>Calle Mozart 201, San Borja 41</td>\n",
       "      <td>2015-09-01 00:00:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  source_latitude  source_longitude  \\\n",
       "0         41037       -12.088156        -77.016065   \n",
       "1        116591       -12.099957        -77.036497   \n",
       "2         86426       -12.099153        -77.019425   \n",
       "3         53610       -12.110271        -77.028945   \n",
       "4        102927       -12.098430        -77.026246   \n",
       "\n",
       "                                   source_address  destination_latitude  \\\n",
       "0  Avenida Nicolás de Arriola 314, La Victoria 13            -12.108531   \n",
       "1     Av Los Conquistadores 392, San Isidro 15073            -12.119686   \n",
       "2     Av. República de Panamá 3537, San Isidro 27            -12.076505   \n",
       "3                           Junín 225, Miraflores            -12.132221   \n",
       "4       Av. República De Colombia 791, San Isidro            -12.099529   \n",
       "\n",
       "   destination_longitude                             destination_address  \\\n",
       "0             -77.044891  Calle Carlos Graña Elisande 340, San Isidro 27   \n",
       "1             -76.999969            Bruselas 228, La Calera De La Merced   \n",
       "2             -77.089305           Av. La Marina cdra. 25, San Miguel 32   \n",
       "3             -77.027021           Calle San Fernando 380, Miraflores 18   \n",
       "4             -76.990486                  Calle Mozart 201, San Borja 41   \n",
       "\n",
       "         request_date  \n",
       "0 2015-09-01 00:00:04  \n",
       "1 2015-09-01 00:00:15  \n",
       "2 2015-09-01 00:00:17  \n",
       "3 2015-09-01 00:00:29  \n",
       "4 2015-09-01 00:00:31  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl = loader.getData()\n",
    "# dfl = dfl.set_index('request_date')\n",
    "# dfl = dfl.asfreq(freq='h')\n",
    "print(len(dfl[dfl.isnull().any(axis=1)]))\n",
    "dfl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampled & Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>requests</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>WindSpeed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-09-01 00:00:00</th>\n",
       "      <td>708</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-01 01:00:00</th>\n",
       "      <td>479</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-01 02:00:00</th>\n",
       "      <td>492</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-01 03:00:00</th>\n",
       "      <td>563</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-01 04:00:00</th>\n",
       "      <td>355</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     requests  Temperature  Precipitation  WindSpeed\n",
       "request_date                                                        \n",
       "2015-09-01 00:00:00       708         16.0            0.0       17.0\n",
       "2015-09-01 01:00:00       479         16.0            0.0       17.0\n",
       "2015-09-01 02:00:00       492         15.0            0.0       18.0\n",
       "2015-09-01 03:00:00       563         15.0            0.0       18.0\n",
       "2015-09-01 04:00:00       355         16.0            0.0       15.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl = loader.getResampledData()\n",
    "# dfl = dfl.set_index('request_date')\n",
    "# dfl = dfl.asfreq(freq='h')\n",
    "print(len(dfl[dfl.isnull().any(axis=1)]))\n",
    "#dfl.reset_index(inplace=True)\n",
    "dfl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpss_test(timeseries):\n",
    "    print ('Results of KPSS Test:')\n",
    "    kpsstest = kpss(timeseries, regression='c')\n",
    "    kpss_output = pd.Series(kpsstest[0:3], index=['Test Statistic','p-value','Lags Used'])\n",
    "    for key,value in kpsstest[3].items():\n",
    "        kpss_output['Critical Value (%s)'%key] = value\n",
    "        #print (kpss_output)\n",
    "    return kpss_output\n",
    "    \n",
    "def adf_test(timeseries):\n",
    "    #Perform Dickey-Fuller test:\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "        #print (dfoutput) \n",
    "    return dfoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of KPSS Test:\n",
      "<class 'pandas.core.series.Series'>\n",
      "Results of KPSS Test:\n",
      "Test Statistic            3.585869\n",
      "p-value                   0.010000\n",
      "Lags Used                28.000000\n",
      "Critical Value (10%)      0.347000\n",
      "Critical Value (5%)       0.463000\n",
      "Critical Value (2.5%)     0.574000\n",
      "Critical Value (1%)       0.739000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "dfkpss = kpss_test(dfl['requests'])\n",
    "print(type(dfkpss))\n",
    "dfkpss2 = kpss_test(dfl['requests'])\n",
    "print(dfkpss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(eleos, eleos)</th>\n",
       "      <th>(eleos, eleos2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test Statistic</th>\n",
       "      <td>3.585869</td>\n",
       "      <td>3.585869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p-value</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lags Used</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Critical Value (10%)</th>\n",
       "      <td>0.347000</td>\n",
       "      <td>0.347000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Critical Value (5%)</th>\n",
       "      <td>0.463000</td>\n",
       "      <td>0.463000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Critical Value (2.5%)</th>\n",
       "      <td>0.574000</td>\n",
       "      <td>0.574000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Critical Value (1%)</th>\n",
       "      <td>0.739000</td>\n",
       "      <td>0.739000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       (eleos, eleos)  (eleos, eleos2)\n",
       "Test Statistic               3.585869         3.585869\n",
       "p-value                      0.010000         0.010000\n",
       "Lags Used                   28.000000        28.000000\n",
       "Critical Value (10%)         0.347000         0.347000\n",
       "Critical Value (5%)          0.463000         0.463000\n",
       "Critical Value (2.5%)        0.574000         0.574000\n",
       "Critical Value (1%)          0.739000         0.739000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew = pd.DataFrame()\n",
    "dfnew['eleos','eleos'] = dfkpss\n",
    "dfnew['eleos','eleos2'] = dfkpss2\n",
    "#dfeleos = pd.merge(dfkpss, dfkpss2)\n",
    "dfnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
